{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "renewable-scroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark as spark\n",
    "from pyspark import SparkContext\n",
    "# initialize a new Spark Context to use for the execution of the script\n",
    "sc = SparkContext(appName=\"MY-APP-NAME\", master=\"local[*]\")\n",
    "# prevent useless logging messages\n",
    "sc.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "spectacular-mountain",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, FloatType, IntegerType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import DecisionTreeRegressor, LinearRegression\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator, MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n",
    "from pyspark.ml.classification import FMClassifier\n",
    "import numpy as np\n",
    "from pyspark.mllib.clustering import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"appName\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "variable-maintenance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_out_timestep(data):\n",
    "    condition = \"u_out == 0\"\n",
    "    filtered = data.filter(condition)\n",
    "    return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dynamic-sellers",
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes a spark dataset containing the variable to regress and time_step\n",
    "#returns slope and intercept \n",
    "def get_linear_parameters(data, name): \n",
    "    # take only the correct time_step until u_out = 0\n",
    "    data = filter_out_timestep(data)\n",
    "    \n",
    "    #adjust name of the feature and label\n",
    "    feature = ['time_step']\n",
    "    lr_data = data.select(col(name).alias(\"label\"), *feature)\n",
    "\n",
    "    #prepare the data and the pipeline\n",
    "    vectorAssembler = VectorAssembler(inputCols=feature, outputCol=\"unscaled_features\")\n",
    "    standardScaler = StandardScaler(inputCol=\"unscaled_features\", outputCol=\"features\")\n",
    "    lr = LinearRegression(maxIter=10, regParam=.01)\n",
    "    stages = [vectorAssembler, standardScaler, lr]\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "\n",
    "    #fit the pipeline\n",
    "    model = pipeline.fit(lr_data)\n",
    "\n",
    "    prediction = model.transform(lr_data)\n",
    "    \n",
    "    #get coefficients\n",
    "    return[model.stages[2].coefficients[0], model.stages[2].intercept]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "limited-framework",
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes a spark dataset containing the variable to regress and time_step\n",
    "#returns slope and intercept \n",
    "def get_logistic_parameters(data, name):\n",
    "    #adjust name of the feature and label\n",
    "    feature = ['time_step']\n",
    "    lr_data = data.select(col(name).alias(\"label\"), *feature)\n",
    "\n",
    "    #prepare the data and the pipeline\n",
    "    vectorAssembler = VectorAssembler(inputCols=feature, outputCol=\"unscaled_features\")\n",
    "    standardScaler = StandardScaler(inputCol=\"unscaled_features\", outputCol=\"features\")\n",
    "    lr = LogisticRegression(maxIter=10, regParam=.01)\n",
    "    stages = [vectorAssembler, standardScaler, lr]\n",
    "    pipeline = Pipeline(stages=stages)\n",
    "\n",
    "    #fit the pipeline\n",
    "    model = pipeline.fit(lr_data)\n",
    "\n",
    "    #get coefficients\n",
    "    return[model.stages[2].coefficients[0], model.stages[2].intercept]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automatic-arcade",
   "metadata": {},
   "source": [
    "### Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "handy-hierarchy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+---+---+--------------------+-------------------+-----+------------------+\n",
      "| id|breath_id|  R|  C|           time_step|               u_in|u_out|          pressure|\n",
      "+---+---------+---+---+--------------------+-------------------+-----+------------------+\n",
      "|  1|        1| 20| 50|                 0.0|0.08333400563464438|    0| 5.837491705069121|\n",
      "|  2|        1| 20| 50|0.033652305603027344| 18.383041472634716|    0|5.9077938505203464|\n",
      "|  3|        1| 20| 50| 0.06751441955566406| 22.509277769756217|    0| 7.876253923154396|\n",
      "|  4|        1| 20| 50| 0.10154223442077637| 22.808822256996738|    0|11.742871922971284|\n",
      "|  5|        1| 20| 50|  0.1357555389404297| 25.355850299494183|    0|12.234986941129785|\n",
      "+---+---------+---+---+--------------------+-------------------+-----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.options(header='true', inferschema='true', delimiter=',').csv(\"data/train.csv\")\n",
    "data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stock-niger",
   "metadata": {},
   "source": [
    "# Pre-process the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "handmade-buffalo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- breath_id: integer (nullable = true)\n",
      " |-- R: string (nullable = true)\n",
      " |-- C: string (nullable = true)\n",
      " |-- time_step: float (nullable = true)\n",
      " |-- u_in: float (nullable = true)\n",
      " |-- u_out: float (nullable = true)\n",
      " |-- pressure: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#cast types\n",
    "df = data.withColumn(\"pressure\",col(\"pressure\").cast(\"float\"))\\\n",
    "    .withColumn(\"u_out\",col(\"u_out\").cast(\"float\"))\\\n",
    "    .withColumn(\"u_in\",col(\"u_in\").cast(\"float\"))\\\n",
    "    .withColumn(\"time_step\",col(\"time_step\").cast(\"float\"))\\\n",
    "    .withColumn(\"breath_id\",col(\"breath_id\").cast(\"int\"))\\\n",
    "    .withColumn(\"id\",col(\"id\").cast(\"int\"))\\\n",
    "    .withColumn(\"R\",col(\"R\").cast(\"string\"))\\\n",
    "    .withColumn(\"C\",col(\"C\").cast(\"string\"))\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-concert",
   "metadata": {},
   "source": [
    "# Deleting negative pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acting-jumping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_negative pressure : 3713\n",
      "n_positive pressure: 6032287\n"
     ]
    }
   ],
   "source": [
    "print (\"n_negative pressure :\",df.filter(df['pressure']< 0).count())\n",
    "print (\"n_positive pressure:\", df.filter(df['pressure']> 0).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "representative-error",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+---+---+-----------+----------+-----+---------+\n",
      "| id|breath_id|  R|  C|  time_step|      u_in|u_out| pressure|\n",
      "+---+---------+---+---+-----------+----------+-----+---------+\n",
      "|  1|        1| 20| 50|        0.0|0.08333401|  0.0|5.8374915|\n",
      "|  2|        1| 20| 50|0.033652306| 18.383041|  0.0| 5.907794|\n",
      "|  3|        1| 20| 50| 0.06751442| 22.509277|  0.0| 7.876254|\n",
      "|  4|        1| 20| 50|0.101542234| 22.808823|  0.0|11.742872|\n",
      "|  5|        1| 20| 50| 0.13575554|  25.35585|  0.0|12.234987|\n",
      "|  6|        1| 20| 50| 0.16969776| 27.259867|  0.0|12.867706|\n",
      "|  7|        1| 20| 50| 0.20370793| 27.127485|  0.0|14.695562|\n",
      "|  8|        1| 20| 50| 0.23772264| 26.807732|  0.0|15.890698|\n",
      "|  9|        1| 20| 50| 0.27177644| 27.864716|  0.0|15.539187|\n",
      "| 10|        1| 20| 50| 0.30573177| 28.313036|  0.0|15.750094|\n",
      "| 11|        1| 20| 50| 0.33967495| 26.866758|  0.0|17.296741|\n",
      "| 12|        1| 20| 50| 0.37368035| 26.762802|  0.0|17.226439|\n",
      "| 13|        1| 20| 50| 0.40765023| 27.993273|  0.0|16.171907|\n",
      "| 14|        1| 20| 50| 0.44180417| 26.789898|  0.0|17.367044|\n",
      "| 15|        1| 20| 50| 0.47610283|  25.63407|  0.0|18.070065|\n",
      "| 16|        1| 20| 50|  0.5099957| 26.280195|  0.0|17.156137|\n",
      "| 17|        1| 20| 50|  0.5440407| 24.726715|  0.0|18.280972|\n",
      "| 18|        1| 20| 50|  0.5781789| 23.467888|  0.0|18.773087|\n",
      "| 19|        1| 20| 50|  0.6121094| 23.858435|  0.0| 17.85916|\n",
      "| 20|        1| 20| 50| 0.64605474| 21.883404|  0.0|19.124598|\n",
      "+---+---------+---+---+-----------+----------+-----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pr=df.filter(df['pressure']>0)\n",
    "df = df_pr\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cosmetic-calvin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_negative pressure : 0\n",
      "n_positive pressure: 6032287\n"
     ]
    }
   ],
   "source": [
    "print (\"n_negative pressure :\",df.filter(df['pressure']< 0).count())\n",
    "print (\"n_positive pressure:\", df.filter(df['pressure']> 0).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "biological-affairs",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- breath_id: integer (nullable = true)\n",
      " |-- R: string (nullable = true)\n",
      " |-- C: string (nullable = true)\n",
      " |-- time_step: float (nullable = true)\n",
      " |-- u_in: float (nullable = true)\n",
      " |-- u_out: float (nullable = true)\n",
      " |-- pressure: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#cast types\n",
    "df = data.withColumn(\"pressure\",col(\"pressure\").cast(\"float\"))\\\n",
    "    .withColumn(\"u_out\",col(\"u_out\").cast(\"float\"))\\\n",
    "    .withColumn(\"u_in\",col(\"u_in\").cast(\"float\"))\\\n",
    "    .withColumn(\"time_step\",col(\"time_step\").cast(\"float\"))\\\n",
    "    .withColumn(\"breath_id\",col(\"breath_id\").cast(\"int\"))\\\n",
    "    .withColumn(\"id\",col(\"id\").cast(\"int\"))\\\n",
    "    .withColumn(\"R\",col(\"R\").cast(\"string\"))\\\n",
    "    .withColumn(\"C\",col(\"C\").cast(\"string\"))\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-origin",
   "metadata": {},
   "source": [
    "# Regressing on u_in, u_out and pressure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "shaped-chapter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75450\n"
     ]
    }
   ],
   "source": [
    "breath_ids = [int(row.breath_id) for row in df.select('breath_id').distinct().collect()]\n",
    "print(len(breath_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "boring-deviation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breath_id: 148\n",
      "u_in regression: coefficient -0.627586555937512, intercept 3.279187855644647\n",
      "pressure regression: coefficient 1.712044550044049, intercept 4.787830588906654\n",
      "u_out regression: coefficient 3.5839924595399673, intercept -4.387057482814503\n",
      "---------------------------------------------------------------------------\n",
      "Breath_id: 463\n",
      "u_in regression: coefficient -2.730341695467989, intercept 11.496348651324867\n",
      "pressure regression: coefficient 5.452311677836793, intercept 14.032851614737082\n",
      "u_out regression: coefficient 3.5980943797891185, intercept -4.875283862177274\n",
      "---------------------------------------------------------------------------\n",
      "Breath_id: 471\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-286cdcdf8faf>\u001b[0m in \u001b[0;36mget_linear_parameters\u001b[0;34m(data, name)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m#fit the pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyspark/ml/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# must be an Estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m                     \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mindexOfLastEstimator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \"\"\"\n\u001b[1;32m    331\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1301\u001b[0m             \u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1303\u001b[0;31m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1031\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m   1198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1200\u001b[0;31m             \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1201\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Answer received: {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 669\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "r, c, m_u_in, q_u_in, m_u_out, q_u_out, m_pressure, q_pressure = ([] for i in range(8))\n",
    "i = 0\n",
    "for b_id in breath_ids: \n",
    "    condition = \"breath_id == \" + str(b_id)\n",
    "    print(f\"Breath_id: {b_id}\")\n",
    "    breath = df.filter(condition) #rows regarding a breath \n",
    "    #train linear regressor on u_in and pressure \n",
    "    u_in_par = get_linear_parameters(breath, 'u_in')\n",
    "    print(f\"u_in regression: coefficient {u_in_par[0]}, intercept {u_in_par[1]}\")\n",
    "    pressure_par = get_linear_parameters(breath, 'pressure')\n",
    "    print(f\"pressure regression: coefficient {pressure_par[0]}, intercept {pressure_par[1]}\")\n",
    "    u_out_par = get_logistic_parameters(breath, 'u_out')\n",
    "    print(f\"u_out regression: coefficient {u_out_par[0]}, intercept {u_out_par[1]}\")\n",
    "    r.append(breath.head()['R'])\n",
    "    c.append(breath.head()['C'])\n",
    "    m_u_in.append(float(u_in_par[0]))\n",
    "    q_u_in.append(float(u_in_par[1]))\n",
    "    m_u_out.append(float(u_out_par[0]))\n",
    "    q_u_out.append(float(u_out_par[1]))\n",
    "    m_pressure.append(float(pressure_par[0]))\n",
    "    q_pressure.append(float(pressure_par[1]))\n",
    "    print('---------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-liverpool",
   "metadata": {},
   "source": [
    "## Rebuilding the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "original-mitchell",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new spark dataframe\n",
    "features = ['breath_ids', 'R', 'C', 'm_u_in', 'q_u_in', 'm_u_out', 'q_u_out', 'm_pressure', 'q_pressure']\n",
    "data = zip(breath_ids, r, c, m_u_in, q_u_in, m_u_out, q_u_out, m_pressure, q_pressure)\n",
    "df_coeff = spark.createDataFrame(data, schema = features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "creative-recall",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+---+------------------+------------------+------------------+------------------+-----------------+------------------+\n",
      "|breath_ids|  R|  C|            m_u_in|            q_u_in|           m_u_out|           q_u_out|       m_pressure|        q_pressure|\n",
      "+----------+---+---+------------------+------------------+------------------+------------------+-----------------+------------------+\n",
      "|       148| 50| 10|-0.627586555937512| 3.279187855644647|3.5839924595399673|-4.387057482814503|1.712044550044049| 4.787830588906654|\n",
      "|       463| 50| 10|-2.730341695467989|11.496348651324867|3.5980943797891185|-4.875283862177274|5.452311677836793|14.032851614737082|\n",
      "+----------+---+---+------------------+------------------+------------------+------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_coeff.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
